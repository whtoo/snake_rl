# ä»£ç è´¨é‡å’Œç»´æŠ¤æ€§å»ºè®®

## å·²å®ç°çš„ä¼˜åŒ–

### âœ… è¾“å…¥å±è”½åŠŸèƒ½
- **åŠŸèƒ½**: è®­ç»ƒæœŸé—´è‡ªåŠ¨å±è”½é”®ç›˜å’Œé¼ æ ‡è¾“å…¥ï¼Œåªå…è®¸ Ctrl+C ä¸­æ–­
- **ä¼˜åŠ¿**: é˜²æ­¢æ„å¤–è¾“å…¥å¹²æ‰°è®­ç»ƒï¼Œæé«˜è®­ç»ƒç¨³å®šæ€§
- **å®ç°**: ä½¿ç”¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨å’Œä¿¡å·å¤„ç†å™¨

### âœ… DirectML æ”¯æŒç§»é™¤
- **åŠŸèƒ½**: ç®€åŒ–è®¾å¤‡é€‰æ‹©é€»è¾‘ï¼Œä¸“æ³¨äº CUDAã€MPS å’Œ CPU
- **ä¼˜åŠ¿**: å‡å°‘ä¾èµ–ï¼Œæé«˜å…¼å®¹æ€§ï¼Œç®€åŒ–ç»´æŠ¤

### âœ… é”™è¯¯ä¿®å¤
- **åŠŸèƒ½**: ä¿®å¤ RainbowAgent epsilon å±æ€§è®¿é—®é”™è¯¯
- **å®ç°**: åŠ¨æ€æ£€æµ‹æ™ºèƒ½ä½“ç±»å‹ï¼Œé€‚é…ä¸åŒçš„æ¢ç´¢ç­–ç•¥

## è¿›ä¸€æ­¥ä¼˜åŒ–å»ºè®®

### ğŸ”§ ä»£ç ç»“æ„ä¼˜åŒ–

#### 1. é…ç½®ç®¡ç†
```python
# å»ºè®®åˆ›å»º config.py
class TrainingConfig:
    def __init__(self):
        self.episodes = 1000
        self.batch_size = 32
        self.learning_rate = 1e-4
        # ... å…¶ä»–é…ç½®
    
    @classmethod
    def from_args(cls, args):
        config = cls()
        for key, value in vars(args).items():
            if hasattr(config, key):
                setattr(config, key, value)
        return config
```

#### 2. æ—¥å¿—ç³»ç»Ÿæ”¹è¿›
```python
# å»ºè®®ä½¿ç”¨ç»“æ„åŒ–æ—¥å¿—
import logging
from datetime import datetime

class TrainingLogger:
    def __init__(self, log_dir):
        self.logger = logging.getLogger('snake_rl')
        handler = logging.FileHandler(f'{log_dir}/training_{datetime.now().strftime("%Y%m%d_%H%M%S")}.log')
        formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
        handler.setFormatter(formatter)
        self.logger.addHandler(handler)
        self.logger.setLevel(logging.INFO)
```

#### 3. å¼‚å¸¸å¤„ç†å¢å¼º
```python
# åœ¨è®­ç»ƒå¾ªç¯ä¸­æ·»åŠ æ›´å¥½çš„å¼‚å¸¸å¤„ç†
try:
    # è®­ç»ƒä»£ç 
except KeyboardInterrupt:
    logger.info("è®­ç»ƒè¢«ç”¨æˆ·ä¸­æ–­")
except torch.cuda.OutOfMemoryError:
    logger.error("GPUå†…å­˜ä¸è¶³ï¼Œå»ºè®®å‡å°‘æ‰¹é‡å¤§å°")
except Exception as e:
    logger.error(f"è®­ç»ƒè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
    # ä¿å­˜å½“å‰çŠ¶æ€
finally:
    # æ¸…ç†èµ„æº
```

### ğŸ“Š æ€§èƒ½ç›‘æ§

#### 1. è®­ç»ƒæŒ‡æ ‡æ‰©å±•
```python
# æ·»åŠ æ›´å¤šç›‘æ§æŒ‡æ ‡
class MetricsTracker:
    def __init__(self):
        self.metrics = {
            'episode_lengths': [],
            'q_values': [],
            'gradient_norms': [],
            'memory_usage': [],
            'training_speed': []
        }
    
    def log_episode_metrics(self, episode_data):
        # è®°å½•è¯¦ç»†çš„è®­ç»ƒæŒ‡æ ‡
        pass
```

#### 2. è‡ªåŠ¨è¶…å‚æ•°è°ƒä¼˜
```python
# å»ºè®®é›†æˆ Optuna æˆ–ç±»ä¼¼å·¥å…·
import optuna

def objective(trial):
    lr = trial.suggest_float('lr', 1e-5, 1e-2, log=True)
    batch_size = trial.suggest_categorical('batch_size', [16, 32, 64, 128])
    # è¿è¡Œè®­ç»ƒå¹¶è¿”å›æ€§èƒ½æŒ‡æ ‡
    return performance_score
```

### ğŸ§ª æµ‹è¯•å’ŒéªŒè¯

#### 1. å•å…ƒæµ‹è¯•æ‰©å±•
```python
# tests/test_training_pipeline.py
import pytest
from unittest.mock import Mock, patch

class TestTrainingPipeline:
    def test_training_loop_interruption(self):
        # æµ‹è¯• Ctrl+C ä¸­æ–­åŠŸèƒ½
        pass
    
    def test_model_saving_loading(self):
        # æµ‹è¯•æ¨¡å‹ä¿å­˜å’ŒåŠ è½½
        pass
    
    def test_epsilon_calculation(self):
        # æµ‹è¯• epsilon è®¡ç®—é€»è¾‘
        pass
```

#### 2. é›†æˆæµ‹è¯•
```python
# tests/test_integration.py
def test_full_training_pipeline():
    # æµ‹è¯•å®Œæ•´çš„è®­ç»ƒæµç¨‹
    args = create_test_args()
    with patch('sys.argv', ['train.py'] + args):
        # è¿è¡ŒçŸ­æœŸè®­ç»ƒæµ‹è¯•
        pass
```

### ğŸ”’ å®‰å…¨æ€§å’Œç¨³å®šæ€§

#### 1. èµ„æºç®¡ç†
```python
# ä½¿ç”¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨ç¡®ä¿èµ„æºæ¸…ç†
class GPUMemoryManager:
    def __enter__(self):
        torch.cuda.empty_cache()
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        torch.cuda.empty_cache()
        if exc_type:
            logger.error(f"GPUæ“ä½œå¼‚å¸¸: {exc_val}")
```

#### 2. æ£€æŸ¥ç‚¹ç³»ç»Ÿ
```python
class CheckpointManager:
    def __init__(self, save_dir, max_checkpoints=5):
        self.save_dir = save_dir
        self.max_checkpoints = max_checkpoints
    
    def save_checkpoint(self, episode, agent, optimizer, metrics):
        checkpoint = {
            'episode': episode,
            'model_state_dict': agent.model.state_dict(),
            'optimizer_state_dict': optimizer.state_dict(),
            'metrics': metrics,
            'timestamp': datetime.now()
        }
        # ä¿å­˜å¹¶ç®¡ç†æ£€æŸ¥ç‚¹æ•°é‡
```

### ğŸ“ˆ å¯è§†åŒ–å’Œåˆ†æ

#### 1. å®æ—¶ç›‘æ§é¢æ¿
```python
# å»ºè®®ä½¿ç”¨ Streamlit æˆ– Dash åˆ›å»ºç›‘æ§é¢æ¿
import streamlit as st
import plotly.graph_objects as go

def create_monitoring_dashboard():
    st.title("Snake RL è®­ç»ƒç›‘æ§")
    
    # å®æ—¶æ˜¾ç¤ºè®­ç»ƒæŒ‡æ ‡
    col1, col2 = st.columns(2)
    with col1:
        st.plotly_chart(create_reward_plot())
    with col2:
        st.plotly_chart(create_loss_plot())
```

#### 2. è®­ç»ƒåˆ†æå·¥å…·
```python
class TrainingAnalyzer:
    def __init__(self, log_dir):
        self.log_dir = log_dir
    
    def analyze_convergence(self):
        # åˆ†ææ”¶æ•›æ€§
        pass
    
    def detect_overfitting(self):
        # æ£€æµ‹è¿‡æ‹Ÿåˆ
        pass
    
    def suggest_hyperparameters(self):
        # åŸºäºå†å²æ•°æ®å»ºè®®è¶…å‚æ•°
        pass
```

### ğŸš€ éƒ¨ç½²å’Œç”Ÿäº§åŒ–

#### 1. Docker å®¹å™¨åŒ–
```dockerfile
# Dockerfile
FROM pytorch/pytorch:latest

WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt

COPY . .
CMD ["python", "src/train.py"]
```

#### 2. CI/CD æµæ°´çº¿
```yaml
# .github/workflows/training.yml
name: Training Pipeline
on:
  push:
    branches: [main]
  pull_request:
    branches: [main]

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: 3.8
      - name: Install dependencies
        run: pip install -r requirements.txt
      - name: Run tests
        run: pytest tests/
      - name: Run training test
        run: python src/train.py --episodes 5 --model dqn
```

## å®æ–½ä¼˜å…ˆçº§

### é«˜ä¼˜å…ˆçº§ ğŸ”´
1. **é…ç½®ç®¡ç†ç³»ç»Ÿ** - æé«˜ä»£ç å¯ç»´æŠ¤æ€§
2. **å¼‚å¸¸å¤„ç†å¢å¼º** - æé«˜è®­ç»ƒç¨³å®šæ€§
3. **æ£€æŸ¥ç‚¹ç³»ç»Ÿ** - é˜²æ­¢è®­ç»ƒè¿›åº¦ä¸¢å¤±

### ä¸­ä¼˜å…ˆçº§ ğŸŸ¡
1. **æ€§èƒ½ç›‘æ§æ‰©å±•** - æ›´å¥½åœ°ç†è§£è®­ç»ƒè¿‡ç¨‹
2. **å•å…ƒæµ‹è¯•å®Œå–„** - ç¡®ä¿ä»£ç è´¨é‡
3. **æ—¥å¿—ç³»ç»Ÿæ”¹è¿›** - ä¾¿äºé—®é¢˜è¯Šæ–­

### ä½ä¼˜å…ˆçº§ ğŸŸ¢
1. **å®æ—¶ç›‘æ§é¢æ¿** - æå‡ç”¨æˆ·ä½“éªŒ
2. **è‡ªåŠ¨è¶…å‚æ•°è°ƒä¼˜** - ä¼˜åŒ–æ¨¡å‹æ€§èƒ½
3. **å®¹å™¨åŒ–éƒ¨ç½²** - ä¾¿äºç¯å¢ƒç®¡ç†

## æ€»ç»“

å½“å‰ä»£ç å·²ç»å…·å¤‡äº†è‰¯å¥½çš„åŸºç¡€ç»“æ„å’ŒåŠŸèƒ½å®Œæ•´æ€§ã€‚é€šè¿‡å®æ–½ä¸Šè¿°å»ºè®®ï¼Œå¯ä»¥è¿›ä¸€æ­¥æå‡ï¼š

- **å¯ç»´æŠ¤æ€§**: é€šè¿‡é…ç½®ç®¡ç†å’Œæ¨¡å—åŒ–è®¾è®¡
- **ç¨³å®šæ€§**: é€šè¿‡å¼‚å¸¸å¤„ç†å’Œæ£€æŸ¥ç‚¹ç³»ç»Ÿ
- **å¯è§‚æµ‹æ€§**: é€šè¿‡æ—¥å¿—å’Œç›‘æ§ç³»ç»Ÿ
- **å¯æµ‹è¯•æ€§**: é€šè¿‡å®Œå–„çš„æµ‹è¯•å¥—ä»¶
- **å¯æ‰©å±•æ€§**: é€šè¿‡æ¨¡å—åŒ–æ¶æ„è®¾è®¡

å»ºè®®æŒ‰ç…§ä¼˜å…ˆçº§é€æ­¥å®æ–½è¿™äº›æ”¹è¿›ï¼Œç¡®ä¿æ¯ä¸ªé˜¶æ®µéƒ½æœ‰æ˜ç¡®çš„ä»·å€¼äº§å‡ºã€‚